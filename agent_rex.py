# This file is auto-generated by organjsm tangle. Do not edit directly.
# Source: index.org

# [[file:index.org::196]]
"""
Agent-Rex: An Async Generator/Iterator Based FRP-Like Library for Python

This library provides composable async stream operators similar to RxJS/Most.js,
built on Python's native async generators.

Example:
  from agent_rex import just, map, filter, pipe, collect

  async def main():
    result = await collect(pipe(
      just(42),
      map(lambda x: x * 2),
    ))
    print(result) # [84]
"""

from __future__ import annotations

import asyncio
from typing import (
  TypeVar, AsyncIterator, AsyncIterable, Callable, Awaitable,
  Optional, Union, List, Tuple, Any, Generic, overload
)
from dataclasses import dataclass
from collections import deque

T = TypeVar('T')
U = TypeVar('U')
S = TypeVar('S')
E = TypeVar('E')
# unnamed ends here

# [[file:index.org::553]]
async def just(value: T) -> AsyncIterator[T]:
  """Creates a stream that emits a single value and then completes."""
  yield value

# Alias for just
of = just
# unnamed ends here

# [[file:index.org::972]]
async def from_future(awaitable: Awaitable[T]) -> AsyncIterator[T]:
  """Creates a stream from an awaitable (coroutine/Future).

  When the awaitable resolves, the stream emits the resolved value and completes.
  """
  value = await awaitable
  yield value

# Alias for API consistency with JavaScript
from_promise = from_future
# unnamed ends here

# [[file:index.org::1295]]
async def from_iter(iterable: Union[AsyncIterable[T], list[T], tuple]) -> AsyncIterator[T]:
  """Creates a stream from an iterable or async iterable.

  Emits each value from the iterable in sequence.
  """
  if hasattr(iterable, '__aiter__'):
    async for item in iterable: yield item
  else:
    for item in iterable: yield item
# unnamed ends here

# [[file:index.org::1655]]
async def periodic(interval_seconds: float) -> AsyncIterator[None]:
  """Creates a stream that emits at regular intervals. To give it a value, combine it with `constant`."""
  while True:
    yield None
    await asyncio.sleep(interval_seconds)
# unnamed ends here

# [[file:index.org::1940]]
async def empty() -> AsyncIterator[Any]:
  """Creates a stream that immediately completes without emitting any values."""
  return
  yield # Makes this a generator
# unnamed ends here

# [[file:index.org::2160]]
async def never() -> AsyncIterator[Any]:
  """Creates a stream that never emits any values and never completes."""
  await asyncio.Event().wait() # Wait forever
  yield # Unreachable, but makes this a generator
# unnamed ends here

# [[file:index.org::2437]]
async def iterate(seed: T, fn: Callable[[T], T]) -> AsyncIterator[T]:
  """Creates a stream that emits an infinite sequence by repeatedly applying a function.

  Args:
    seed: Initial value to emit and feed into fn
    fn: Function applied to each value to produce the next
  """
  current = seed
  while True:
    yield current
    current = fn(current)
# unnamed ends here

# [[file:index.org::2778]]
@dataclass
class UnfoldResult(Generic[T, S]):
  """Result of an unfold step."""
  value: T
  next_seed: S
  done: bool


async def unfold(
  seed: S,
  fn: Callable[[S], UnfoldResult[T, S]]
) -> AsyncIterator[T]:
  """Creates a stream by unfolding a seed value. The function returns an object containing the next value, next seed, and done flag."""
  current_seed = seed
  while True:
    result = fn(current_seed)
    if result.done:
      return
    yield result.value
    current_seed = result.next_seed
# unnamed ends here

# [[file:index.org::3226]]
async def start_with(value: T, stream: AsyncIterable[T]) -> AsyncIterator[T]:
  """Prepends a value to the beginning of a stream."""
  yield value
  async for item in stream:
    yield item
# unnamed ends here

# [[file:index.org::3501]]
async def concat(*streams: AsyncIterable[T]) -> AsyncIterator[T]:
  """Concatenates multiple streams into a single stream."""
  for stream in streams:
    async for item in stream:
      yield item
# unnamed ends here

# [[file:index.org::3989]]

# unnamed ends here

# [[file:index.org::4210]]
def pipe(initial: T, *fns: Callable) -> Any:
  """Composes functions left-to-right, passing the result of each to the next.

  The first argument is the initial value; subsequent arguments are unary functions.

  Example:
    result = pipe(
      from_iter([1, 2, 3, 4, 5]),
      filter(lambda x: x % 2 == 0),
      map(lambda x: x * 10),
      take(2),
    )
  """
  from functools import reduce
  return reduce(lambda acc, fn: fn(acc), fns, initial)
# unnamed ends here

# [[file:index.org::4392]]
@overload
def map(fn: Callable[[T], Union[U, Awaitable[U]]]) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def map(fn: Callable[[T], Union[U, Awaitable[U]]], stream: AsyncIterable[T]) -> AsyncIterator[U]: ...

def map(fn: Callable[[T], Union[U, Awaitable[U]]], stream: Optional[AsyncIterable[T]] = None):
  """Transforms each value emitted by a stream using a provided function."""
  async def _map(s: AsyncIterable[T]) -> AsyncIterator[U]:
    async for item in s:
      result = fn(item)
      if asyncio.iscoroutine(result):
        yield await result
      else:
        yield result # type: ignore

  if stream is None:
    return _map
  return _map(stream)
# unnamed ends here

# [[file:index.org::4775]]
@overload
def constant(value: U) -> Callable[[AsyncIterable[Any]], AsyncIterator[U]]: ...
@overload
def constant(value: U, stream: AsyncIterable[Any]) -> AsyncIterator[U]: ...

def constant(value: U, stream: Optional[AsyncIterable[Any]] = None):
  """Creates a stream that emits a constant value for each item in the source stream."""
  async def _constant(s: AsyncIterable[Any]) -> AsyncIterator[U]:
    async for _ in s:
      yield value

  if stream is None:
    return _constant
  return _constant(stream)
# unnamed ends here

# [[file:index.org::5100]]
@overload
def scan(
  accumulator: Callable[[U, T], Union[U, Awaitable[U]]],
  seed: U
) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def scan(
  accumulator: Callable[[U, T], Union[U, Awaitable[U]]],
  seed: U,
  stream: AsyncIterable[T]
) -> AsyncIterator[U]: ...

def scan(
  accumulator: Callable[[U, T], Union[U, Awaitable[U]]],
  seed: U,
  stream: Optional[AsyncIterable[T]] = None
):
  """Accumulates values using an accumulator function, emitting each intermediate result. Yields the seed first, then each accumulated value."""
  async def _scan(s: AsyncIterable[T]) -> AsyncIterator[U]:
    acc = seed
    yield acc
    async for item in s:
      result = accumulator(acc, item)
      if asyncio.iscoroutine(result):
        acc = await result
      else:
        acc = result # type: ignore
      yield acc

  if stream is None:
    return _scan
  return _scan(stream)
# unnamed ends here

# [[file:index.org::5547]]
@overload
def tap(fn: Callable[[T], Any]) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def tap(fn: Callable[[T], Any], stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def tap(fn: Callable[[T], Any], stream: Optional[AsyncIterable[T]] = None):
  """Performs side effects for each value without modifying them.

  The side effect is fired without awaiting.
  """
  async def _tap(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      fn(item) # Fire and forget
      yield item

  if stream is None:
    return _tap
  return _tap(stream)
# unnamed ends here

# [[file:index.org::5881]]
@overload
def await_tap(fn: Callable[[T], Awaitable[Any]]) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def await_tap(fn: Callable[[T], Awaitable[Any]], stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def await_tap(fn: Callable[[T], Awaitable[Any]], stream: Optional[AsyncIterable[T]] = None):
  """Performs side effects for each value, awaiting completion before yielding."""
  async def _await_tap(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      await fn(item)
      yield item

  if stream is None:
    return _await_tap
  return _await_tap(stream)
# unnamed ends here

# [[file:index.org::6209]]
@overload
def continue_with(
  f: Callable[[], AsyncIterable[T]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def continue_with(
  f: Callable[[], AsyncIterable[T]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def continue_with(
  f: Callable[[], AsyncIterable[T]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Continues a stream with another stream once the first completes."""
  async def _continue_with(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      yield item
    async for item in f():
      yield item

  if stream is None:
    return _continue_with
  return _continue_with(stream)
# unnamed ends here

# [[file:index.org::6586]]
async def concat_all(stream_of_streams: AsyncIterable[AsyncIterable[T]]) -> AsyncIterator[T]:
  """Flattens a stream of streams by concatenating them into a single stream."""
  async for stream in stream_of_streams:
    async for item in stream:
      yield item
# unnamed ends here

# [[file:index.org::6898]]
@overload
def concat_map(
  f: Callable[[T], AsyncIterable[U]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def concat_map(
  f: Callable[[T], AsyncIterable[U]],
  stream: AsyncIterable[T]
) -> AsyncIterator[U]: ...

def concat_map(
  f: Callable[[T], AsyncIterable[U]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Maps each value to a stream and concatenates the results in order."""
  async def _concat_map(s: AsyncIterable[T]) -> AsyncIterator[U]:
    async for item in s:
      async for inner_item in f(item):
        yield inner_item

  if stream is None:
    return _concat_map
  return _concat_map(stream)
# unnamed ends here

# [[file:index.org::7232]]
@overload
def filter(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def filter(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def filter(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Filters values based on a predicate function."""
  async def _filter(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      result = predicate(item)
      if asyncio.iscoroutine(result):
        if await result:
          yield item
      elif result:
        yield item

  if stream is None:
    return _filter
  return _filter(stream)
# unnamed ends here

# [[file:index.org::7686]]
async def skip_repeats(stream: AsyncIterable[T]) -> AsyncIterator[T]:
  """Filters out consecutive duplicate values from a stream."""
  first = True
  last_value: Optional[T] = None
  async for item in stream:
    if first or item != last_value:
      yield item
      last_value = item
      first = False
# unnamed ends here

# [[file:index.org::7800]]
@overload
def skip_repeats_with(
  equals: Callable[[T, T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def skip_repeats_with(
  equals: Callable[[T, T], Union[bool, Awaitable[bool]]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def skip_repeats_with(
  equals: Callable[[T, T], Union[bool, Awaitable[bool]]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Filters out consecutive duplicates using a custom equality function."""
  async def _skip_repeats_with(s: AsyncIterable[T]) -> AsyncIterator[T]:
    first = True
    last_value: Optional[T] = None
    async for item in s:
      if first:
        yield item
        last_value = item
        first = False
      else:
        result = equals(item, last_value) # type: ignore
        if asyncio.iscoroutine(result):
          is_equal = await result
        else:
          is_equal = result
        if not is_equal:
          yield item
          last_value = item

  if stream is None:
    return _skip_repeats_with
  return _skip_repeats_with(stream)
# unnamed ends here

# [[file:index.org::8279]]
@overload
def take(n: int) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def take(n: int, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def take(n: int, stream: Optional[AsyncIterable[T]] = None):
  """Takes only the first n values from a stream."""
  async def _take(s: AsyncIterable[T]) -> AsyncIterator[T]:
    count = 0
    async for item in s:
      if count < n:
        yield item
        count += 1
      else:
        break

  if stream is None:
    return _take
  return _take(stream)
# unnamed ends here

# [[file:index.org::8630]]
@overload
def skip(n: int) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def skip(n: int, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def skip(n: int, stream: Optional[AsyncIterable[T]] = None):
  """Skips the first n values from a stream."""
  async def _skip(s: AsyncIterable[T]) -> AsyncIterator[T]:
    count = 0
    async for item in s:
      if count >= n:
        yield item
      count += 1

  if stream is None:
    return _skip
  return _skip(stream)
# unnamed ends here

# [[file:index.org::9003]]
@overload
def slice(start: int, end: int) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def slice(start: int, end: int, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def slice(start: int, end: int, stream: Optional[AsyncIterable[T]] = None):
  """Emits values from index start to end (exclusive)."""
  async def _slice(s: AsyncIterable[T]) -> AsyncIterator[T]:
    index = 0
    async for item in s:
      if index >= start and index < end:
        yield item
      index += 1
      if index >= end:
        break

  if stream is None:
    return _slice
  return _slice(stream)
# unnamed ends here

# [[file:index.org::9384]]
@overload
def take_while(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def take_while(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def take_while(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Takes values while predicate returns true, stops at first false."""
  async def _take_while(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      result = predicate(item)
      if asyncio.iscoroutine(result):
        if await result:
          yield item
        else:
          break
      elif result:
        yield item
      else:
        break

  if stream is None:
    return _take_while
  return _take_while(stream)
# unnamed ends here

# [[file:index.org::9777]]
@overload
def skip_while(
 predicate: Callable[[T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def skip_while(
 predicate: Callable[[T], Union[bool, Awaitable[bool]]],
 stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def skip_while(
 predicate: Callable[[T], Union[bool, Awaitable[bool]]],
 stream: Optional[AsyncIterable[T]] = None
):
  """Skips values while predicate is true, then emits the rest."""
  async def _skip_while(s: AsyncIterable[T]) -> AsyncIterator[T]:
    skipping = True
    async for item in s:
      if skipping:
        result = predicate(item)
        if asyncio.iscoroutine(result):
          should_skip = await result
        else:
          should_skip = result
        if not should_skip:
          skipping = False
          yield item
      else:
        yield item

  if stream is None:
    return _skip_while
  return _skip_while(stream)
# unnamed ends here

# [[file:index.org::10177]]
@overload
def take_until(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def take_until(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def take_until(
  predicate: Callable[[T], Union[bool, Awaitable[bool]]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Takes values until predicate matches (matching value not emitted)."""
  async def _take_until(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      result = predicate(item)
      if asyncio.iscoroutine(result):
        if await result:
          break
      elif result:
        break
      yield item

  if stream is None:
    return _take_until
  return _take_until(stream)
# unnamed ends here

# [[file:index.org::10571]]
@overload
def delay(seconds: float) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def delay(seconds: float, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def delay(seconds: float, stream: Optional[AsyncIterable[T]] = None):
  """Delays each value by a specified duration."""
  async def _delay(s: AsyncIterable[T]) -> AsyncIterator[T]:
    async for item in s:
      await asyncio.sleep(seconds)
      yield item

  if stream is None:
    return _delay
  return _delay(stream)
# unnamed ends here

# [[file:index.org::11003]]
@overload
def debounce(seconds: float) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def debounce(seconds: float, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def debounce(seconds: float, stream: Optional[AsyncIterable[T]] = None):
  """Only emits a value if no new value arrives within the specified duration."""
  async def _debounce(s: AsyncIterable[T]) -> AsyncIterator[T]:
    pending: Optional[T] = None
    pending_task: Optional[asyncio.Task] = None
    done = False
    result_queue: asyncio.Queue[Optional[T]] = asyncio.Queue()

    async def emit_after_delay(value: T):
      await asyncio.sleep(seconds)
      await result_queue.put(value)

    async def consume_source():
      nonlocal pending, pending_task, done
      async for item in s:
        if pending_task:
          pending_task.cancel()
          try:
            await pending_task
          except asyncio.CancelledError:
            pass
        pending = item
        pending_task = asyncio.create_task(emit_after_delay(item))
      done = True
      if pending_task:
        try:
          await pending_task
        except asyncio.CancelledError:
          pass
      await result_queue.put(None) # Signal completion

    consumer_task = asyncio.create_task(consume_source())

    while True:
      value = await result_queue.get()
      if value is None:
        break
      yield value

    await consumer_task

  if stream is None:
    return _debounce
  return _debounce(stream)
# unnamed ends here

# [[file:index.org::11619]]
@dataclass
class ThrottleOptions:
  """Options for throttle behavior."""
  leading: bool = True
  trailing: bool = True


@overload
def throttle(
  seconds: float,
  options: Optional[ThrottleOptions] = None
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def throttle(
  seconds: float,
  options: Optional[ThrottleOptions],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def throttle(
  seconds: float,
  options: Optional[ThrottleOptions] = None,
  stream: Optional[AsyncIterable[T]] = None
):
  """Limits the rate of emissions with leading/trailing edge control."""
  opts = options or ThrottleOptions()

  async def _throttle(s: AsyncIterable[T]) -> AsyncIterator[T]:
    import time
    last_emit_time = 0.0
    trailing_value: Optional[T] = None
    has_trailing = False

    async for item in s:
      now = time.time()
      elapsed = now - last_emit_time

      if elapsed >= seconds:
        if opts.leading:
          yield item
          last_emit_time = now
          has_trailing = False
        else:
          trailing_value = item
          has_trailing = True
      else:
        trailing_value = item
        has_trailing = True

    if has_trailing and opts.trailing:
      yield trailing_value # type: ignore

  if stream is None:
    if options is None:
      return _throttle
    # Handle case where options might be the stream
    if hasattr(options, '__aiter__'):
      return _throttle(options) # type: ignore
    return _throttle
  return _throttle(stream)
# unnamed ends here

# [[file:index.org::12290]]
@overload
def recover_with(
  recover_fn: Callable[[Exception], AsyncIterable[T]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def recover_with(
  recover_fn: Callable[[Exception], AsyncIterable[T]],
  stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def recover_with(
  recover_fn: Callable[[Exception], AsyncIterable[T]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Recovers from errors by switching to an alternative stream."""
  async def _recover_with(s: AsyncIterable[T]) -> AsyncIterator[T]:
    try:
      async for item in s:
        yield item
    except Exception as e:
      async for item in recover_fn(e):
        yield item

  if stream is None:
    return _recover_with
  return _recover_with(stream)
# unnamed ends here

# [[file:index.org::12712]]

# unnamed ends here

# [[file:index.org::12916]]
async def throw_error(error: Exception) -> AsyncIterator[Any]:
  """Creates a stream that immediately throws an error."""
  raise error
  yield # Makes this a generator
# unnamed ends here

# [[file:index.org::13259]]
@dataclass
class RetryOptions:
  """Options for retry behavior."""
  max_attempts: int = 3
  delay_seconds: float = 0.0
  should_retry: Optional[Callable[[Exception, int], bool]] = None


@overload
def retry(
  options: Union[RetryOptions, int]
) -> Callable[[Callable[[], AsyncIterable[T]]], AsyncIterator[T]]: ...
@overload
def retry(
  options: Union[RetryOptions, int],
  stream_factory: Callable[[], AsyncIterable[T]]
) -> AsyncIterator[T]: ...

def retry(
  options: Union[RetryOptions, int],
  stream_factory: Optional[Callable[[], AsyncIterable[T]]] = None
):
  """Retries a stream factory when it errors."""
  opts = RetryOptions(max_attempts=options) if isinstance(options, int) else options

  async def _retry(factory: Callable[[], AsyncIterable[T]]) -> AsyncIterator[T]:
    attempt = 0
    while True:
      try:
        async for item in factory():
          yield item
        return # Success
      except Exception as e:
        attempt += 1
        should_retry = opts.should_retry(e, attempt) if opts.should_retry else True
        if attempt >= opts.max_attempts or not should_retry:
          raise
        if opts.delay_seconds > 0:
          await asyncio.sleep(opts.delay_seconds)

  if stream_factory is None:
    return _retry
  return _retry(stream_factory)
# unnamed ends here

# [[file:index.org::14070]]
async def merge(*streams: AsyncIterable[T]) -> AsyncIterator[T]:
  """Merges multiple streams into one, emitting values as they arrive."""
  async def consume_stream(
    stream: AsyncIterable[T],
    queue: asyncio.Queue[Tuple[int, Optional[T], bool, Optional[Exception]]],
    index: int
  ):
    try:
      async for item in stream:
        await queue.put((index, item, False, None))
      await queue.put((index, None, True, None)) # Signal completion
    except Exception as e:
      await queue.put((index, None, True, e))

  queue: asyncio.Queue[Tuple[int, Optional[T], bool, Optional[Exception]]] = asyncio.Queue()
  tasks = [asyncio.create_task(consume_stream(stream, queue, i)) for i, stream in enumerate(streams)]

  active = len(streams)
  try:
    while active > 0:
      index, value, done, error = await queue.get()
      if error:
        raise error
      if done:
        active -= 1
      else:
        yield value # type: ignore
  finally:
    for task in tasks:
      task.cancel()
# unnamed ends here

# [[file:index.org::14497]]
async def merge_all(stream_of_streams: AsyncIterable[AsyncIterable[T]]) -> AsyncIterator[T]:
  """Flattens a stream of streams by merging them concurrently."""
  queue: asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]] = asyncio.Queue()
  active_count = 0
  outer_done = False
  tasks: List[asyncio.Task] = []

  async def consume_inner(stream: AsyncIterable[T]):
    nonlocal active_count
    try:
      async for item in stream:
        await queue.put((item, False, None))
    except Exception as e:
      await queue.put((None, True, e))
    finally:
      active_count -= 1
      if outer_done and active_count == 0:
        await queue.put((None, True, None)) # All done

  async def consume_outer():
    nonlocal outer_done, active_count
    async for inner_stream in stream_of_streams:
      active_count += 1
      task = asyncio.create_task(consume_inner(inner_stream))
      tasks.append(task)
    outer_done = True
    if active_count == 0:
      await queue.put((None, True, None)) # No inner streams

  outer_task = asyncio.create_task(consume_outer())
  tasks.append(outer_task)

  try:
    while True:
      value, done, error = await queue.get()
      if error:
        raise error
      if done:
        break
      yield value # type: ignore
  finally:
    for task in tasks:
      task.cancel()
# unnamed ends here

# [[file:index.org::14843]]
@overload
def chain(
  fn: Callable[[T], AsyncIterable[U]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def chain(
  fn: Callable[[T], AsyncIterable[U]],
  stream: AsyncIterable[T]
) -> AsyncIterator[U]: ...

def chain(
  fn: Callable[[T], AsyncIterable[U]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Maps each value to a stream and merges results concurrently."""
  async def _chain(s: AsyncIterable[T]) -> AsyncIterator[U]:
    async def mapped_streams():
      async for item in s:
        yield fn(item)

    async for result in merge_all(mapped_streams()):
      yield result

  if stream is None:
    return _chain
  return _chain(stream)

# Alias for chain
flat_map = chain
# unnamed ends here

# [[file:index.org::15336]]
@overload
def switch_map(
  fn: Callable[[T], AsyncIterable[U]]
) -> Callable[[AsyncIterable[T]], AsyncIterator[U]]: ...
@overload
def switch_map(
  fn: Callable[[T], AsyncIterable[U]],
  stream: AsyncIterable[T]
) -> AsyncIterator[U]: ...

def switch_map(
  fn: Callable[[T], AsyncIterable[U]],
  stream: Optional[AsyncIterable[T]] = None
):
  """Maps each value to a stream, cancelling previous inner stream on new outer value."""
  async def _switch_map(s: AsyncIterable[T]) -> AsyncIterator[U]:
    current_task: Optional[asyncio.Task] = None
    queue: asyncio.Queue[Tuple[Optional[U], bool, bool]] = asyncio.Queue()
    outer_done = False

    async def consume_inner(inner: AsyncIterable[U], generation: int):
      try:
        async for item in inner:
          await queue.put((item, False, False))
      except asyncio.CancelledError:
        pass
      finally:
        await queue.put((None, True, False)) # Inner done

    async def consume_outer(s: AsyncIterable[T]):
      nonlocal current_task, outer_done
      generation = 0
      async for item in s:
        if current_task:
          current_task.cancel()
        generation += 1
        current_task = asyncio.create_task(consume_inner(fn(item), generation))
      outer_done = True
      await queue.put((None, False, True)) # Outer done

    outer_task = asyncio.create_task(consume_outer(s))
    inner_done = True

    try:
      while True:
        value, is_inner_done, is_outer_done = await queue.get()
        if is_outer_done and inner_done:
          break
        if is_inner_done:
          inner_done = True
          if outer_done:
            break
        elif is_outer_done:
          if inner_done:
            break
        else:
          inner_done = False
          yield value # type: ignore
    finally:
      outer_task.cancel()
      if current_task:
        current_task.cancel()

  if stream is None:
    return _switch_map
  return _switch_map(stream)
# unnamed ends here

# [[file:index.org::15808]]
async def latest(*streams: AsyncIterable[T]) -> AsyncIterator[Tuple[T, ...]]:
  """Combines streams, emitting tuple of latest values when any emits."""
  latest_values: List[Optional[T]] = [None] * len(streams)
  has_value: List[bool] = [False] * len(streams)
  queue: asyncio.Queue[Tuple[int, Optional[T], bool, Optional[Exception]]] = asyncio.Queue()

  async def consume_stream(stream: AsyncIterable[T], index: int):
    try:
      async for item in stream:
        await queue.put((index, item, False, None))
      await queue.put((index, None, True, None))
    except Exception as e:
      await queue.put((index, None, True, e))

  tasks = [asyncio.create_task(consume_stream(stream, i)) for i, stream in enumerate(streams)]

  active = len(streams)
  try:
    while active > 0:
      index, value, done, error = await queue.get()
      if error:
        raise error
      if done:
        active -= 1
      else:
        latest_values[index] = value
        has_value[index] = True
        if all(has_value):
          yield tuple(latest_values) # type: ignore
  finally:
    for task in tasks:
      task.cancel()
# unnamed ends here

# [[file:index.org::16204]]
async def apply_latest(
  fn_stream: AsyncIterable[Callable[[T], U]],
  value_stream: AsyncIterable[T]
) -> AsyncIterator[U]:
  """Applies the latest function to the latest value."""
  async for fn, value in latest(fn_stream, value_stream): # type: ignore
    yield fn(value)
# unnamed ends here

# [[file:index.org::16503]]
@overload
def until_stream(
  stop_stream: AsyncIterable[Any]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def until_stream(
  stop_stream: AsyncIterable[Any],
  source_stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def until_stream(
  stop_stream: AsyncIterable[Any],
  source_stream: Optional[AsyncIterable[T]] = None
):
  """Emits from source until stop stream emits."""
  async def _until_stream(source: AsyncIterable[T]) -> AsyncIterator[T]:
    stop_signal = asyncio.Event()

    async def watch_stop():
      async for _ in stop_stream:
        stop_signal.set()
        break

    stop_task = asyncio.create_task(watch_stop())

    try:
      async for item in source:
        if stop_signal.is_set():
          break
        yield item
    finally:
      stop_task.cancel()

  if source_stream is None:
    return _until_stream
  return _until_stream(source_stream)
# unnamed ends here

# [[file:index.org::16872]]
@overload
def since_stream(
  start_stream: AsyncIterable[Any]
) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def since_stream(
  start_stream: AsyncIterable[Any],
  source_stream: AsyncIterable[T]
) -> AsyncIterator[T]: ...

def since_stream(
  start_stream: AsyncIterable[Any],
  source_stream: Optional[AsyncIterable[T]] = None
):
  """Emits from source only after start stream emits."""
  async def _since_stream(source: AsyncIterable[T]) -> AsyncIterator[T]:
    started = asyncio.Event()

    async def watch_start():
      async for _ in start_stream:
        started.set()
        break

    start_task = asyncio.create_task(watch_start())

    try:
      async for item in source:
        if started.is_set():
          yield item
    finally:
      start_task.cancel()

  if source_stream is None:
    return _since_stream
  return _since_stream(source_stream)
# unnamed ends here

# [[file:index.org::17240]]
@overload
def buffer(size: int) -> Callable[[AsyncIterable[T]], AsyncIterator[List[T]]]: ...
@overload
def buffer(size: int, stream: AsyncIterable[T]) -> AsyncIterator[List[T]]: ...

def buffer(size: int, stream: Optional[AsyncIterable[T]] = None):
  """Collects values into lists of the specified size."""
  async def _buffer(s: AsyncIterable[T]) -> AsyncIterator[List[T]]:
    buf: List[T] = []
    async for item in s:
      buf.append(item)
      if len(buf) >= size:
        yield buf
        buf = []
    if buf:
      yield buf

  if stream is None:
    return _buffer
  return _buffer(stream)
# unnamed ends here

# [[file:index.org::17641]]
@overload
def buffer_time(seconds: float) -> Callable[[AsyncIterable[T]], AsyncIterator[List[T]]]: ...
@overload
def buffer_time(seconds: float, stream: AsyncIterable[T]) -> AsyncIterator[List[T]]: ...

def buffer_time(seconds: float, stream: Optional[AsyncIterable[T]] = None):
  """Collects values over a time window."""
  async def _buffer_time(s: AsyncIterable[T]) -> AsyncIterator[List[T]]:
    buf: List[T] = []
    done = False
    queue: asyncio.Queue[Tuple[Optional[T], bool, bool]] = asyncio.Queue()

    async def timer():
      while not done:
        await asyncio.sleep(seconds)
        await queue.put((None, True, False)) # Timer tick

    async def consume():
      nonlocal done
      async for item in s:
        await queue.put((item, False, False))
      done = True
      await queue.put((None, False, True)) # Source done

    timer_task = asyncio.create_task(timer())
    consume_task = asyncio.create_task(consume())

    try:
      while True:
        value, is_tick, is_done = await queue.get()
        if is_done:
          if buf:
            yield buf
          break
        elif is_tick:
          if buf:
            yield buf
            buf = []
        else:
          buf.append(value) # type: ignore
    finally:
      timer_task.cancel()
      consume_task.cancel()

  if stream is None:
    return _buffer_time
  return _buffer_time(stream)
# unnamed ends here

# [[file:index.org::18125]]
@overload
def window(size: int) -> Callable[[AsyncIterable[T]], AsyncIterator[AsyncIterable[T]]]: ...
@overload
def window(size: int, stream: AsyncIterable[T]) -> AsyncIterator[AsyncIterable[T]]: ...

def window(size: int, stream: Optional[AsyncIterable[T]] = None):
  """Splits the source into windows of the specified size."""
  async def _window(s: AsyncIterable[T]) -> AsyncIterator[AsyncIterable[T]]:
    async for batch in buffer(size, s):
      async def window_stream(items: List[T]) -> AsyncIterator[T]:
        for item in items:
          yield item
      yield window_stream(batch)

  if stream is None:
    return _window
  return _window(stream)
# unnamed ends here

# [[file:index.org::18560]]
@overload
def eager(buffer_size: int) -> Callable[[AsyncIterable[T]], AsyncIterator[T]]: ...
@overload
def eager(buffer_size: int, stream: AsyncIterable[T]) -> AsyncIterator[T]: ...

def eager(buffer_size: int, stream: Optional[AsyncIterable[T]] = None):
  """Pre-fetches values from a slow producer into a buffer."""
  async def _eager(s: AsyncIterable[T]) -> AsyncIterator[T]:
    queue: asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]] = asyncio.Queue(
      maxsize=buffer_size if buffer_size > 0 else 0
    )

    async def consume():
      try:
        async for item in s:
          await queue.put((item, False, None))
        await queue.put((None, True, None))
      except Exception as e:
        await queue.put((None, True, e))

    task = asyncio.create_task(consume())

    try:
      while True:
        value, done, error = await queue.get()
        if error:
          raise error
        if done:
          break
        yield value # type: ignore
    finally:
      task.cancel()

  if stream is None:
    return _eager
  return _eager(stream)

def eager_now(buffer_size: int, stream: AsyncIterable[T]) -> AsyncIterable[T]:
  """Pre-fetches values immediately on creation."""
  queue: asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]] = asyncio.Queue(
    maxsize=buffer_size if buffer_size > 0 else 0
  )
  started = False
  task: Optional[asyncio.Task] = None

  async def consume():
    try:
      async for item in stream:
        await queue.put((item, False, None))
      await queue.put((None, True, None))
    except Exception as e:
      await queue.put((None, True, e))

  async def start():
    nonlocal started, task
    if not started:
      started = True
      task = asyncio.create_task(consume())

  # Start immediately
  asyncio.get_event_loop().call_soon(lambda: asyncio.create_task(start()))

  async def iterate() -> AsyncIterator[T]:
    await start()
    while True:
      value, done, error = await queue.get()
      if error:
        raise error
      if done:
        break
      yield value # type: ignore

  return iterate()
# unnamed ends here

# [[file:index.org::19133]]
class ReplaySubject(Generic[T]):
  """A multicasting subject that replays buffered values to new subscribers."""

  def __init__(self, buffer_size: int = float('inf')): # type: ignore
    self._buffer: deque[T] = deque(maxlen=buffer_size if buffer_size != float('inf') else None)
    self._subscribers: List[asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]]] = []
    self._completed = False
    self._error: Optional[Exception] = None

  def next(self, value: T) -> None:
    """Push a value to all subscribers."""
    if self._completed:
      raise RuntimeError("Cannot push to completed ReplaySubject")

    self._buffer.append(value)
    for sub in self._subscribers:
      sub.put_nowait((value, False, None))

  def complete(self) -> None:
    """Signal completion to all subscribers."""
    self._completed = True
    for sub in self._subscribers:
      sub.put_nowait((None, True, None))

  def throw(self, error: Exception) -> None:
    """Signal an error to all subscribers."""
    self._error = error
    self._completed = True
    for sub in self._subscribers:
      sub.put_nowait((None, True, error))

  def __aiter__(self) -> AsyncIterator[T]:
    queue: asyncio.Queue[Tuple[Optional[T], bool, Optional[Exception]]] = asyncio.Queue()

    # Add buffered values
    for value in self._buffer:
      queue.put_nowait((value, False, None))

    if self._completed:
      queue.put_nowait((None, True, self._error))
    else:
      self._subscribers.append(queue)

    async def iterate() -> AsyncIterator[T]:
      try:
        while True:
          value, done, error = await queue.get()
          if error:
            raise error
          if done:
            break
          yield value # type: ignore
      finally:
        if queue in self._subscribers:
          self._subscribers.remove(queue)

    return iterate()

  def get_buffer(self) -> List[T]:
    """Get the current buffer contents."""
    return list(self._buffer)

  @property
  def subscriber_count(self) -> int:
    """Number of active subscribers."""
    return len(self._subscribers)
# unnamed ends here

# [[file:index.org::19554]]
def replay(buffer_size: int, source: AsyncIterable[T]) -> AsyncIterable[T]:
  """Makes a stream consumable by multiple consumers by buffering values."""
  subject = ReplaySubject[T](buffer_size)
  started = False

  async def start_source():
    nonlocal started
    if started:
      return
    started = True

    try:
      async for value in source:
        subject.next(value)
      subject.complete()
    except Exception as e:
      subject.throw(e)

  class ReplayIterable:
    def __aiter__(self):
      asyncio.create_task(start_source())
      return subject.__aiter__()

  return ReplayIterable()
# unnamed ends here

# [[file:index.org::20076]]
def share(source: AsyncIterable[T]) -> AsyncIterable[T]:
  """Shares a stream without buffering."""
  return replay(0, source)
# unnamed ends here

# [[file:index.org::20453]]
def replay_factory(
  buffer_size: int,
  source: AsyncIterable[T]
) -> Callable[[], AsyncIterable[T]]:
  """Creates a factory that produces independent copies of a buffered stream."""
  subject = ReplaySubject[T](buffer_size)
  started = False

  async def start_source():
    nonlocal started
    if started:
      return
    started = True

    try:
      async for value in source:
        subject.next(value)
      subject.complete()
    except Exception as e:
      subject.throw(e)

  def factory() -> AsyncIterable[T]:
    asyncio.create_task(start_source())
    return subject

  return factory
# unnamed ends here

# [[file:index.org::20843]]
async def replay_stream(
  buffer_size: int,
  source: AsyncIterable[T]
) -> AsyncIterator[AsyncIterable[T]]:
  """Returns a stream that emits independent copies of the source stream."""
  factory = replay_factory(buffer_size, source)
  while True:
    yield factory()
# unnamed ends here

# [[file:index.org::21613]]
__all__ = [
  # Creation
  'just', 'of', 'from_promise', 'from_iter', 'periodic', 'empty', 'never',
  'iterate', 'unfold', 'start_with', 'concat',

  # Composition
  'pipe',

  # Transformation
  'map', 'constant', 'scan', 'tap', 'await_tap', 'continue_with',
  'concat_all', 'concat_map',

  # Filtering
  'filter', 'skip_repeats', 'skip_repeats_with',

  # Slicing
  'take', 'skip', 'slice', 'take_while', 'skip_while', 'take_until',

  # Time
  'delay', 'debounce', 'throttle', 'ThrottleOptions',

  # Error handling
  'recover_with', 'throw_error', 'retry', 'RetryOptions',

  # Concurrent
  'merge', 'merge_all', 'chain', 'flat_map', 'switch_map',
  'latest', 'apply_latest', 'until_stream', 'since_stream',

  # Buffering
  'buffer', 'buffer_time', 'window', 'eager', 'eager_now',

  # Multicasting
  'ReplaySubject', 'replay', 'share', 'replay_factory', 'replay_stream',

  # Types
  'UnfoldResult',
]
# unnamed ends here
